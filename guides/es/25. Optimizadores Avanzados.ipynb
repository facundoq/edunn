{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import numpy as np\n",
    "import edunn as nn\n",
    "from edunn import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo falso con un vector de parámetros con valor inicial [0,0] y gradientes que siempre son [1,-11]\n",
    "model = nn.FakeModel(parameter=np.array([0,0]),gradient=np.array([1, -1]))\n",
    "# función de error falso cuyo error es siempre 1 y las derivadas también\n",
    "error = nn.FakeError(error=1,derivative_value=1)\n",
    "\n",
    "# Conjunto de datos falso, que no se utilizará realmente\n",
    "fake_samples = 3\n",
    "fake_x = np.random.rand(fake_samples,10)\n",
    "fake_y = np.random.rand(fake_samples,5)\n",
    "\n",
    "# Optimizar el modelo por 1 época con lr=2\n",
    "optimizer = nn.RMSprop(batch_size=fake_samples,epochs=1,lr=2,shuffle=False)\n",
    "history = optimizer.optimize(model,fake_x,fake_y,error,verbose=False)\n",
    "expected_parameters=np.array([-19,19])\n",
    "utils.check_same(expected_parameters,model.get_parameters()[\"parameter\"])\n",
    "\n",
    "# Optimizar el modelo por 1 época *adicional* con lr=2\n",
    "history = optimizer.optimize(model,fake_x,fake_y,error,verbose=False)\n",
    "expected_parameters=np.array([-33,33])\n",
    "utils.check_same(expected_parameters,model.get_parameters()[\"parameter\"])\n",
    "    \n",
    "# Optimizar el modelo por 3 épocas más, ahora con con lr=1    \n",
    "optimizer = nn.RMSprop(batch_size=fake_samples,epochs=3,lr=1,shuffle=False)\n",
    "history = optimizer.optimize(model,fake_x,fake_y,error,verbose=False)\n",
    "expected_parameters=np.array([-54,54])\n",
    "utils.check_same(expected_parameters,model.get_parameters()[\"parameter\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelo falso con un vector de parámetros con valor inicial [0,0] y gradientes que siempre son [1,-11]\n",
    "model = nn.FakeModel(parameter=np.array([0,0]),gradient=np.array([1, -1]))\n",
    "# función de error falso cuyo error es siempre 1 y las derivadas también\n",
    "error = nn.FakeError(error=1,derivative_value=1)\n",
    "\n",
    "# Conjunto de datos falso, que no se utilizará realmente\n",
    "fake_samples = 3\n",
    "fake_x = np.random.rand(fake_samples,10)\n",
    "fake_y = np.random.rand(fake_samples,5)\n",
    "\n",
    "# Optimizar el modelo por 1 época con lr=2\n",
    "optimizer = nn.Adam(batch_size=fake_samples,epochs=1,lr=2,shuffle=False)\n",
    "history = optimizer.optimize(model,fake_x,fake_y,error,verbose=False)\n",
    "expected_parameters=np.array([-1,1])\n",
    "utils.check_same(expected_parameters,model.get_parameters()[\"parameter\"])\n",
    "\n",
    "# Optimizar el modelo por 1 época *adicional* con lr=2\n",
    "history = optimizer.optimize(model,fake_x,fake_y,error,verbose=False)\n",
    "expected_parameters=np.array([-3,3])\n",
    "utils.check_same(expected_parameters,model.get_parameters()[\"parameter\"])\n",
    "    \n",
    "# Optimizar el modelo por 3 épocas más, ahora con con lr=1    \n",
    "optimizer = nn.Adam(batch_size=fake_samples,epochs=3,lr=1,shuffle=False)\n",
    "history = optimizer.optimize(model,fake_x,fake_y,error,verbose=False)\n",
    "expected_parameters=np.array([-5,5])\n",
    "utils.check_same(expected_parameters,model.get_parameters()[\"parameter\"])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comprobaciones mediante entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y,classes=nn.datasets.load_classification(\"mnist\")\n",
    "# normalización de los datos\n",
    "x = (x-x.mean())/x.std()\n",
    "n, din = x.shape\n",
    "# calcular cantidad de clases\n",
    "classes = y.max()+1\n",
    "print(\"Tamaños de x e y:\", x.shape,y.shape)\n",
    "x.min(), x.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim=32\n",
    "#Red con dos capas \n",
    "model = nn.Sequential([nn.Dense(din,hidden_dim,activation_name=\"relu\"),\n",
    "                       nn.Dense(hidden_dim,classes,activation_name=\"softmax\"),\n",
    "                      ])\n",
    "\n",
    "error = nn.MeanError(nn.CrossEntropyWithLabels())\n",
    "optimizer = nn.RMSprop(lr=0.01,epochs=100,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo de optimización\n",
    "history = optimizer.optimize(model,x,y,error)\n",
    "nn.plot.plot_history(history,error_name=error.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Métricas del modelo:\")\n",
    "y_pred=model.forward(x)\n",
    "y_pred_labels=nn.utils.onehot2labels(y_pred)\n",
    "nn.metrics.classification_summary(y,y_pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_dim=32\n",
    "#Red con dos capas \n",
    "model = nn.Sequential([nn.Dense(din,hidden_dim,activation_name=\"relu\"),\n",
    "                       nn.Dense(hidden_dim,classes,activation_name=\"softmax\"),\n",
    "                      ])\n",
    "\n",
    "error = nn.MeanError(nn.CrossEntropyWithLabels())\n",
    "optimizer = nn.Adam(lr=0.01,epochs=100,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Algoritmo de optimización\n",
    "history = optimizer.optimize(model,x,y,error)\n",
    "nn.plot.plot_history(history,error_name=error.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Métricas del modelo:\")\n",
    "y_pred=model.forward(x)\n",
    "y_pred_labels=nn.utils.onehot2labels(y_pred)\n",
    "nn.metrics.classification_summary(y,y_pred_labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "captum",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
