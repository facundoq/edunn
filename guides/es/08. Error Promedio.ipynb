{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from edunn import utils\n",
    "import edunn as nn\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error medio o promedio\n",
    "\n",
    "Si bien la capa SquaredError nos permite calcular los errores de cada ejemplo, para obtener una medida del error respecto a un lote o conjunto de ejemplos, tenemos que calcular el promedio de estos errores. Como este cálculo es independiente de la función de error, podemos encapsularlo en su propia clase. Implementar el método `forward` de la clase error medio.\n",
    "\n",
    "Nota: Muchas veces a la función de error también se la llama _loss_, para distinguirla del error promedio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([[2,-2],\n",
    "             [-4,4]])\n",
    "y_true = np.array([[3,3],\n",
    "             [-5,2]])\n",
    "\n",
    "\n",
    "layer=nn.MeanError(nn.SquaredError())\n",
    "E=15.5\n",
    "utils.check_same_float(E,layer.forward(y,y_true),title=\"mean error\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward\n",
    "\n",
    "Para avanzar más rápido, y porque contiene algún truquillo, el paso `backward` ya está implementado, pero te sugerimos pensar como lo implementarías y luego compararlo la implementación de referencia."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
