{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librería **simplenn**\n",
    "\n",
    "[simplenn](https://github.com/facundoq/simplenn) es una librería de uso didáctico para comprender como se implementan las redes neuronales modernas en frameworks como [Keras](https://keras.io/) o [Pytorch](https://pytorch.org/). Fue diseñada para ser simple de entender e _implementar_. También es simple de utilizar. Por ejemplo, para definir y entrenar una red neuronal para clasificación con de tres capas con distintas funciones de activación, podemos escribir un código muy similar al de estos frameworks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown dataset boston. Valid choices for classification datasets:\n dict_keys(['iris', 'study1d', 'study2d', 'study2d_easy']).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2cb98961b5ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"boston\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/nn/datasets/__init__.py\u001b[0m in \u001b[0;36mload_classification\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_classification\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"classification\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/dev/nn/datasets/__init__.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(dataset_name, loaders, title)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mCallable\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdataset_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Unknown dataset {dataset_name}. Valid choices for {title} datasets:\\n {loaders.keys()}.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mdataset_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdataset_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown dataset boston. Valid choices for classification datasets:\n dict_keys(['iris', 'study1d', 'study2d', 'study2d_easy'])."
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import datasets\n",
    "\n",
    "dataset_name=\"boston\"\n",
    "x,y,classes = datasets.load_classification(dataset_name)\n",
    "x -= x.mean(axis=0)\n",
    "x /= x.std(axis=0)\n",
    "n,din=x.shape\n",
    "n_classes=y.max()+1\n",
    "\n",
    "\n",
    "\n",
    "import simplenn as sn\n",
    "\n",
    "# Definición del modelo\n",
    "layers = [sn.Linear(din,10),\n",
    "          sn.Bias(10),\n",
    "          sn.ReLU(),\n",
    "          sn.Linear(10,20),\n",
    "          sn.Bias(20),\n",
    "          sn.TanH(),\n",
    "          sn.Linear(20,n_classes),\n",
    "          sn.Bias(n_classes),\n",
    "          sn.Softmax()\n",
    "          ]\n",
    "error = sn.MeanError(sn.CrossEntropyWithLabels())\n",
    "model = sn.Sequential(layers,error)\n",
    "print(\"Arquitectura de la Red:\")\n",
    "print(model.summary())\n",
    "\n",
    "# Algoritmo de optimización\n",
    "gd = sn.GradientDescent(lr=0.1)\n",
    "\n",
    "# Algoritmo de optimización\n",
    "history = model.fit(x,y,epochs=100,batch_size=16,optimizer=gd)\n",
    "sn.plot.plot_history(history)\n",
    "\n",
    "\n",
    "# Reporte del desempeño\n",
    "y_pred = model.predict(x)\n",
    "y_pred_labels = y_pred.argmax(axis=1)\n",
    "print(f\"Accuracy final del modelo: {sn.measures.accuracy(y,y_pred)*100:0.2f}%\")\n",
    "\n",
    "\n",
    "if din ==2:\n",
    "    # Visualización del modelo\n",
    "    sn.plot.plot_model_dataset_2d_classification(x,y,model,title=dataset_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Componentes de la librería\n",
    "\n",
    "Describimos los componentes básicos de la librería utilizados en el código anterior, para proveer el contexto de los ejercicios a realizar. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Módulo **datasets**\n",
    "\n",
    "\n",
    "El módulo `datasets` que permite cargar algunos conjuntos de datos de prueba fácilmente, de modo de verificar y experimentar con los modelos\n",
    "\n",
    "```python\n",
    "dataset_name=\"study_2d_easy\"\n",
    "x,y,classes = datasets.load(dataset_name)\n",
    "x -= x.mean(axis=0)\n",
    "x /= x.std(axis=0)\n",
    "n,din=x.shape\n",
    "n_classes=y.max()+1\n",
    "```\n",
    "\n",
    "Para ver qué otros conjuntos de datos tiene este módulo, podés ejecutar `datasets.get_names()` y obtener una lista de nombres de conjuntos de datos que soporta el módulo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los conjuntos de datos disponibles son:\n",
      "['iris', 'study_1d', 'study_2d', 'study_2d_easy', 'study_regression_1d', 'boston', 'red_wine', 'white_wine']\n",
      "\n",
      "Clases del dataset iris:\n",
      "['setosa', 'versicolor', 'virginica']\n"
     ]
    }
   ],
   "source": [
    "print(\"Los conjuntos de datos disponibles son:\")\n",
    "print(datasets.get_names())\n",
    "print()\n",
    "\n",
    "# Ejemplo de carga de otro dataset\n",
    "x,y,classes=datasets.load(\"iris\")\n",
    "print(\"Clases del dataset iris:\")\n",
    "print(classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clases y módulos de simplenn\n",
    "\n",
    "Para usar `simplenn`, importamos la librería y la llamamos `sn` de modo que sea más legible su uso.\n",
    "```python\n",
    "import simplenn as sn\n",
    "```\n",
    "\n",
    "La librería tiene varias clases para crear modelos:\n",
    "\n",
    "\n",
    "* Las clases `Linear`, `Bias`, que permiten crear capas con las funciones $wx$ y $x+b$ respectivamente. En estos casos, $w$ y $b$ son parámetros a optimizar. Combinando estas capas se puede formar una capa densa tradicional que calcula $wx+b$.\n",
    "* Las clases`TanH`, `ReLU` y `Softmax`, que permiten crear capas con las funciones de activación de esos nombres.\n",
    "* La clase `CrossEntropyWithLabels`, una capa que permite calcular el error de la red basado en entropía cruzada  _para cada ejemplo_. Esta capa además se combina con `MeanError` que permite calcular el error promedio de otra capa de error que calcula el mismo _para cada ejemplo_, como la capa `CrossEntropyWithLabels` que mencionamos, u otras como `MeanSquaredError` para el error cuadrático medio.\n",
    "* La clase `Sequential` para crear redes secuenciales, donde donde la salida de cada capa es la entrada de la capa siguiente, y hay solo una capa inicial y una final.\n",
    "    * Esta clase además necesita una capa de error para crearse, de modo de poder entrenar la misma.\n",
    "\n",
    "```python\n",
    "layers = [sn.Linear(din,10),\n",
    "          sn.Bias(10),\n",
    "          sn.ReLU(),\n",
    "          sn.Linear(10,20),\n",
    "          sn.Bias(20),\n",
    "          sn.TanH(),\n",
    "          sn.Linear(20,n_classes),\n",
    "          sn.Bias(n_classes),\n",
    "          sn.Softmax()\n",
    "          ]\n",
    "error = sn.MeanError(sn.CrossEntropyWithLabels())\n",
    "model = sn.Sequential(layers,error)\n",
    "```\n",
    "\n",
    "Además, tiene clases y métodos para entrenarlos:\n",
    "\n",
    "* La clase `Sequential` tiene el método `fit` que permite, dados arreglos `x` e `y`, entrenar un modelo para minimizar su error en este conjunto de datos. \n",
    "* Para este entrenamiento, debe especificarse un algoritmo de optimización. En este caso utilizamos descenso de gradiente simple con la clase `GradientDescent`, una tasa de aprendizaje de `0.1`, `100` épocas y un tamaño de lote de 16.\n",
    "\n",
    "```python\n",
    "# Algoritmo de optimización\n",
    "gd = sn.GradientDescent(lr=0.1)\n",
    "\n",
    "# Algoritmo de optimización\n",
    "history = model.fit(x,y,epochs=100,batch_size=16,optimizer=gd)\n",
    "```\n",
    "\n",
    "Por último, podemos utilizar y evaluar el modelo:\n",
    "* El método `predict` permite obtener las predicciones del modelo. \n",
    "    * La salida obtenida es la de la última capa, sin el error\n",
    "    * Para un problema de clasificación, debemos calcular el argmax ya que la salida son probabilidades de clase para cada ejemplo.\n",
    "* El módulo `measures` tiene algunas funciones para evaluar métricas de desempeño del mismo.\n",
    "* El módulo `plot` tiene algunas funciones para monitorear el entrenamiento del modelo (`plot_history`) y, en el caso en que el problema sea de pocas dimensiones (1 o 2), también visualizar las fronteras de decisión o la función ajustada (`plot_model_dataset_2d_classification`)\n",
    "\n",
    "```python\n",
    "sn.plot.plot_history(history)\n",
    "\n",
    "y_pred = model.predict(x)\n",
    "y_pred_labels = y_pred.argmax(axis=1)\n",
    "print(f\"Accuracy final del modelo: {sn.measures.accuracy(y,y_pred)*100:0.2f}%\")\n",
    "\n",
    "if din ==2:\n",
    "    # Visualización del modelo\n",
    "    sn.plot.plot_model_dataset_2d_classification(x,y,model,title=dataset_name)\n",
    "```\n",
    "\n",
    "Como habrás notado, si bien podemos definir así la red y ejecutar el método `fit` para pedirle al modelo que se entrene con descenso de gradiente, esta red no aprende, ya que no están implementados correctamente ninguno de los métodos correspondientes de las capas y algoritmos de aprendizaje. \n",
    "\n",
    "Tu objetivo es implementar las distintas capas de la librería `simplenn`, así como algunos inicializadores y algoritmos de optimización.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementación de referencia \n",
    "\n",
    "El [repositorio de simplenn](https://github.com/facundoq/simplenn) contiene una implementación de referencia, que se enfoca en ser fácil de entender, y no en la eficiencia de cómputo.\n",
    "\n",
    "En base al código de esa implementación de referencia, y un programa que lo procesa, se generó una versión de simplenn en donde se quitaron partes cruciales de la implementación de cada capa y otras clases.\n",
    "\n",
    "Para poder reimplementar la librería, tendrás que buscar las líneas de código entre los comentarios `\"\"\" COMPLETAR COMIENZO \"\"\"` y `\"\"\" COMPLETAR FIN \"\"\"` y completar con el código correspondiente.\n",
    "\n",
    "En todos los casos, es importante enfocarse en buscar una implementación fácil de entender y que sea correcta, y dejar de lado la eficiencia para una implementación posterior.\n",
    "\n",
    "Si bien esta guía de implementación está en español, la implementación de la librería se ha realizado en inglés para que sea más fácil relacionar los conceptos con los de otras librerías.\n",
    "\n",
    "Los siguientes notebooks te guiarán en la implementación de cada capa, tanto en el método forward y el backward, y métodos importantes de otras clases.\n",
    "\n",
    "En caso de duda, siempre puedes consultar la [implementación de referencia](https://github.com/facundoq/simplenn)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
